# Redis单处理线程浅析

## 前言

Redis不是单线程，但Redis命令处理是单线程。

Redis为什么要用单线程？

- 局限：耗时操作、阻塞操作会大大降低单线程的处理效率。

## 1.Redis是如何处理单线程问题下的耗时操作的

解决阻塞操作，包括两个层面的阻塞问题。

### 1.1 io层面

#### 1.1.1 磁盘读写

磁盘读写，也就是持久化存储，想办法让主进程避开耗时操作，有两个解决方案：

- 1.aof，另起线程进行持久化。持久化的是命令操作协议，是基于对内存的操作进行持久化。

  - 包含很多重复的数据，较慢。例如，我先写入一行数据，后续又把她删了，在aof中就是两条数据，而在dfb中就没有这条数据。
  - 分两个步骤：
    - 写入到**内核**高速缓存page cache，速度快，可以不用异步
    - 缓存刷入磁盘中，太慢，另开线程处理，调用bio_aof_fsync

- 2.rdb，另起进程进行持久化。持久化的内存中的数据结构，是基于内存的最终状态进行持久化。速度更快。

  - ```mermaid
    graph LR
    id1[app-server] --写操作,例如增删改-->id2(app-client/redis-server)
    id2 --in--> id5[memory]
    id2 --fork--> id3{children thread}
    id2 --占有--> id4(父进程拥有的虚拟地址空间)
    id3 --占有--> id4(父进程拥有的虚拟地址空间) 
    ```
  
- fork相当于给当前redis-server做了一个快照，在给新线程分配新的页表项之前，他和父进程指向同一个内存地址，共享那一块数据。
  
- Redis利用了子进程这个特点：在遇到需要处理的耗时io操作时，fork出一个子进程，用于处理之前指向的那块内存地址的读写事件。

#### 1.1.2 网络io

网络io

- 采用reactor网络模型，使用并发处理的网络io**检测**
  - 将并发的网络io请求，转发到io多路复用模块处理
  - 当io就绪，以事件通知的方式，让需要io结果的线程获取结果，继续执行
- 将对io操作的处理转化为对事件的处理（e.g，epoll event）
- 减少对线程的占用，即减少等待时间，采用通知的方式，让线程高效运作。

### 1.2 cpu层面

cpu层面的数据组织方式：散列表（数据量增加不会影响操作效率）

#### 1.1.2.1 Redis数据组织方式

- Redis是kv数据库（使用数据库的方式：通过key去操作value），内存数据库（所有数据在内存中，易失性），也是数据结构数据库（操作的value，支持不同类型的数据结构，包括string，list，hash，set，zset）。
- Redis的数据组织方式：16个db，每个db内由支持数据结构的kv对组成，具体如下所示：
- ![image-20230926210639174](C:\Users\8208191402\Desktop\笔记\图片\image-20230926210639174.png)
- 对于每一个key，通过simple hash生成一个64位的数，对8取余之后，放在对应数组下标处的链表上，然后对这个key下面再挂载一个value，可以是复杂数据结构，包括字符串、跳表等等
- 采用hash/散列表，通过key寻找value的时间复杂度是O（1）

#### 1.1.2.2 Redis dict数据结构分析

- dictEntry的数据结构，表示dict的一个元素，dictEntry是唯一的。

```c
typedef struct dictEntry {
    void *key;
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;
    struct dictEntry *next;//解决hash冲突，同一个值会出现多个相同hash值的数据结构，
    //因此使用拉链法解决hash冲突。
} dictEntry;
```

- dict的数据结构

```c
/* This is our hash table structure. Every dictionary has two of this as we
 * implement incremental rehashing, for the old to the new table. */
//意思就是，hash的指针数组会在使用中不断扩容，使用
typedef struct dictht {
    dictEntry **table;
    unsigned long size;
    unsigned long sizemask;
    unsigned long used;
} dictht;

typedef struct dict {
    dictType *type;
    void *privdata;
    dictht ht[2];//一个dict准备两个指针数组
    long rehashidx; /* rehashing not in progress if rehashidx == -1 */
    unsigned long iterators; /* number of iterators currently running */
} dict;
```

- 为什么需要两个hash数组？

  - hash函数会在使用过程中，出现更多冲突，到达某一阈值时，需要进行数组扩容。数组的复制是较慢的，而且这个hash数组在内存中，如果到需要时才分配空间，可能出现内存不够的情况。

  - 同时，重新分配指针数组之后，需要对原来的数据进行rehash，原来的index也需要对应的更新。

  - 因此hash为了解决内存中，大数据迁移的问题，使用分治的方法，设置两个hash数组，渐进式rehash。

    - 分治，小数组的数据，无法快速迁移到新的大数组中
      - 1.网络发送增删改查请求时，分步优化
      - 2.cpu不繁忙时，定时优化
    - 渐进式rehash

  - 首先检测是否需要expand

  - ```c
    /* Expand the hash table if needed */
    static int _dictExpandIfNeeded(dict *d)
    {
        /* Incremental rehashing already in progress. Return. */
        if (dictIsRehashing(d)) return DICT_OK;
    
        /* If the hash table is empty expand it to the initial size. */
        if (d->ht[0].size == 0) return dictExpand(d, DICT_HT_INITIAL_SIZE);
    
        /* If we reached the 1:1 ratio, and we are allowed to resize the hash
         * table (global setting) or we should avoid it but the ratio between
         * elements/buckets is over the "safe" threshold, we resize doubling
         * the number of buckets. */
        if ((dict_can_resize == DICT_RESIZE_ENABLE && //hash数组允许扩容
             d->ht[0].used >= d->ht[0].size) ||		  //当前数组元素大于等于数组大小
            (dict_can_resize != DICT_RESIZE_FORBID && //hash数组不允许主动扩容，但可以扩容
             d->ht[0].used / d->ht[0].size > dict_force_resize_ratio)){
            //负载因子(used/size)>阈值
            return dictExpand(d, d->ht[0].used*2);//执行扩容操作
        }
        return DICT_OK;
    }
    ```

  - 然后进行扩容

  - ```c
    /* Expand or create the hash table */
    int dictExpand(dict *d, unsigned long size){
        /* the size of new dict is invalid if it is smaller than the number of
         * elements already inside the hash table */
    	//如果数组正在进行渐进式rehash；或者数组已有元素>要分配的空间大小，则返回扩展失败。
        if (dictIsRehashing(d) || d->ht[0].used > size)
            return DICT_ERR;
    
        dictht n; /* the new hash table */
        // 函数会计算新的实际尺寸 realsize，将它设置为大于等于指定的扩展尺寸的下一个 2 的幂次方。
        // 这是为了方便处理哈希函数计算出的索引值。
        unsigned long realsize = _dictNextPower(size);
    
        /* 新尺寸和原尺寸一样，说明不需要要扩展 */
        if (realsize == d->ht[0].size) return DICT_ERR;
    
        /* Allocate the new hash table and initialize all pointers to NULL */
        n.size = realsize;
        n.sizemask = realsize-1;//用于计算hash值索引
        n.table = zcalloc(realsize*sizeof(dictEntry*));//数组
        n.used = 0;//已用大小
    
        /* 第一次初始化哈希表，即不需要进行渐进式 rehash，因此将新哈希表 n 赋值给 d->ht[0] */
        if (d->ht[0].table == NULL) {
            d->ht[0] = n;
            return DICT_OK;
        }
        /* 否则把新分配的数组放到第二个位置上，初始化rehash index，表示准备好进行rehash */
        d->ht[1] = n;
        d->rehashidx = 0;
        return DICT_OK;
    }
    ```

  - 扩容后进行rehash（扩容时因，rehash是果，这个操作费时）

  

#### 1.1.2.3 Redis dict rehash



  - rehash的触发条件：增删改查的时候，都会进行rehash，也就是服务器每发起一次请求，无论什么操作，客户端内存中的redis server都会进行一次rehash。

    - 把rehash操作，放在网络流的处理过程中

      把这个耗cpu的操作，**分布在网络处理的过程中**，每次rehash执行一部分工作，通过rehashindex进行记录

    - ```mermaid
      graph LR
      id1(app-server)--request-->id2(app-client/redis-server)
      id2--rehash-->id2
      ```

      

    

  - ![image-20230927134515431](C:\Users\8208191402\Desktop\笔记\图片\image-20230927134515431.png)

  - ![image-20230927134526740](C:\Users\8208191402\Desktop\笔记\图片\image-20230927134526740.png)

  - ![image-20230927134536292](C:\Users\8208191402\Desktop\笔记\图片\image-20230927134536292.png)

  - ![image-20230927134546310](C:\Users\8208191402\Desktop\笔记\图片\image-20230927134546310.png)

  - ```c
    /* Performs N steps of incremental rehashing. 通过rehashindex实现分步
     * Returns 1 if there are still keys to move from the old to the new hash table,
     * otherwise 0 is returned.
     *
     * Note that a rehashing step consists in moving a bucket (that may have more
     * than one key as we use chaining) from the old to the new hash table, however
     * since part of the hash table may be composed of empty spaces, it is not
     * guaranteed that this function will rehash even a single bucket, since it
     * will visit at max N*10 empty buckets in total, otherwise the amount of
     * work it does would be unbound and the function may block for a long time. */
    int dictRehash(dict *d, int n) {
        int empty_visits = n*10; /* Max number of empty buckets to visit. */
        if (dict_can_resize == DICT_RESIZE_FORBID || !dictIsRehashing(d)) return 0;
        if (dict_can_resize == DICT_RESIZE_AVOID && 
            (d->ht[1].size / d->ht[0].size < dict_force_resize_ratio))
        {
            return 0;
        }
    
        while(n-- && d->ht[0].used != 0) {
            dictEntry *de, *nextde;
    
            /* Note that rehashidx can't overflow as we are sure there are more
             * elements because ht[0].used != 0 */
            assert(d->ht[0].size > (unsigned long)d->rehashidx);
            while(d->ht[0].table[d->rehashidx] == NULL) {
                d->rehashidx++;
                if (--empty_visits == 0) return 1;
            }
            de = d->ht[0].table[d->rehashidx];
            /* Move all the keys in this bucket from the old to the new hash HT */
            while(de) {
                uint64_t h;
    
                nextde = de->next;
                /* Get the index in the new hash table */
                h = dictHashKey(d, de->key) & d->ht[1].sizemask;
                de->next = d->ht[1].table[h];
                d->ht[1].table[h] = de;
                d->ht[0].used--;
                d->ht[1].used++;
                de = nextde;
            }
            d->ht[0].table[d->rehashidx] = NULL;
            d->rehashidx++;
        }
    
        /* Check if we already rehashed the whole table... */
        if (d->ht[0].used == 0) {
            zfree(d->ht[0].table);
            d->ht[0] = d->ht[1];
            _dictReset(&d->ht[1]);
            d->rehashidx = -1;
            return 0;
        }
    
        /* More to rehash... */
        return 1;
    }
    ```

  - 另一个rehash触发条件，cpu空闲时，调取一个时钟周期进行rehash操作，一次执行较多的rehash操作。

  - ```c
    /* Rehash in ms+"delta" milliseconds. The value of "delta" is larger 
     * than 0, and is smaller than 1 in most cases. The exact upper bound 
     * depends on the running time of dictRehash(d,100).*/
    int dictRehashMilliseconds(dict *d, int ms) {
        long long start = timeInMilliseconds();
        int rehashes = 0;
    
        while(dictRehash(d,100)) {
            rehashes += 100;
            if (timeInMilliseconds()-start > ms) break;
        }
        return rehashes;
    }
    ```
#### 1.1.2.4 总结



  - ![image-20230927142515575](C:\Users\8208191402\Desktop\笔记\图片\image-20230927142515575.png)

  - ![image-20230927141327554](C:\Users\8208191402\Desktop\笔记\图片\image-20230927141327554.png)

    

    

### 1.3 对象模型

基于对象模型，采用不同的数据结构实现。

- 当对象包含数据量较少，Redis更关注内存管理；当数据较多，Redis更关注CPU操作时间和销率。
- 例如，当set对象数据较少，使用整数数组，用紧凑的存储方式节省内存；当数据较多，使用dict来存储，查询更改更加高效。

Redis value编码

- ![image-20230927141227464](C:\Users\8208191402\Desktop\笔记\图片\image-20230927141227464.png)

  - 双向链表/quick list和压缩链表/ziplist or listpack的区别：快速链表是基于压缩链表的，也就是快速链表的节点是压缩链表。

  - 测试：

  - ![image-20230927142043563](C:\Users\8208191402\Desktop\笔记\图片\image-20230927142043563.png)

  - ![image-20230927142251303](C:\Users\8208191402\Desktop\笔记\图片\image-20230927142251303.png)

## 2.多线程限制

如果使用多线程，会导致锁的碰撞和cpu频繁上下文切换

- 数据结构在不同数据量的情况下会经常转换，会导致加锁复杂。
- rehash时，同一个数据可能同时在原数组和新分配的数组中，那么查询节点时（增删改都需要先查），需要锁住原来的数组和新的数组，相当于把整个内存Redis DB的table都锁住了，锁粒度太大，相当于是单线程。
- cpu频繁切换上下文，额外开销

