@[TOC](Knowledge Vault :一种互联网规模的概率知识融合KB)

# keywords

知识抽取，概率模型，机器学习

# Abstract

> 目前的知识库：Wikipedia，YAGO，Google‘s knowledge graph

> 设计目的：扩大知识获取的规模。

> 设计方式：把互联网获取的内容（content）和知识库的先验知识（prior knowledge）结合
>
> 通过监督学习来融合异种数据源的知识。

> 特点：规模大，通过计算事实正确性的校准规律。

# Introduction

> 目前的知识库数据，大都来自人工输入和对现有知识库的结构化数据的融合。
>
> 这些数据大都是head content（对应于长尾模型），即常见实体的常用属性
>
> 我们的目的是，构建能够自动从整个互联网抽取数据来augment（增加）数据量。
>
> 现在的问题：传统的方法会产生高噪声，不切实际的事实数据。
>
> 我们希望，我们的模型能自动的利用现有的，已编目的知识，构建关于事实正确性的先验模型。

> 目标：构建全网规模的概率知识库模型。



> 存储结构：RDF三元组 <subject，predicate，object>，例如</id_subject，/people/person/place_of_birth，/id_object>
>
> 每个三元组有一个置信度confidence score，表示知识库“相信”三元组是正确的概率。

> 实体类型和关系来自一个固定的**本体概念**，这个概念应该来自开放的信息抽取渠道（open IE）这一点和传统知识库是一致的，例如Reverb，一个词汇层面的本体概念。
>
> 网络的表示往往会有冗余，例如A是B的家乡和B出生在A。
>
> KV通过把事实和关于事实的词汇表示分开，因此KV是一个独立于语言表示的，结构化知识数据库。

## 本文贡献

- 把网络上含噪声知识的提取，和知识库的先验知识（本文采用Freebase），类比于从混合声音信号中提取特定语言的信号，通过结合语言模型特征。
  - 先验知识可以像处理数据库自身的知识一样，判断网络提取的知识的准确性。例如，网络上提取到奥巴马出生在非洲，模型根据他是美国总统这条已有知识，判断这条知识是错误的。原因可能是语义上的（实体统一和指代消解），也可能是网络本身不可信（降低该网址的知识权值）。
  - 规模大，数据来源包含：自由文本（2.1），HTML 文档树，HTML网络表，人为注释过的网页；KV有1/3的可信三元组来自于网络提取的知识。
  - 尝试了不同的知识抽取方法和先验模型，选取了closed world assumption；选择结合多重互补的系统和数据源（multiple complementary systems and data source）

## 系统概览

KV包含三部分

- 知识提取器

> 每个三元组对应一个提取器，提取器给三元组一个置信度，表示关系和对应声明的可靠性。

- graph-based priors

> 利用知识库的已有三元组，估计新三元组的先验概率。

$$
P(confidence_{web}|confidence_{KB})
$$

- 知识融合

> 基于不同先验和不同提取器的置信度，计算某个三元组的置信度。

>  总的来说，KV要构造一个带权重的，有标签的，稀疏的图（E×P×E matrix G），G（s，p，o）=1，当且仅当存在从s到o的某种连接p，我们的问题也就变成了：对所有候选三元组，计算先验概率：

$$
Pr(G(s,p,o))=1|.)\\
.=\left\{
\begin{aligned}
test \quad feature,triples \in web \quad extraction\\
knowledge \quad edges,triples \in Freebase \quad graph\\
\end{aligned}
\right.
$$

> 最后的知识融合部分，二者都会被考虑。

# body

## 1.Evaluation protocal

> 为了确保某些过于常见的关系p不会占满整个知识库表示，对每个predicate设置一个instance上限。

> 训练集中确保不会有重复的边，但是对于<s，p，o’>，可能存在<s，p‘，o>或<s，p，o>或<s’，p，o>。
>
> 我们通过随机删除边来检测我们的模型对于这些边存在的感知程度。
>
> 本文的相信（believe）指置信度大于0.9的triple。

> 随机删除边也可以用于生成测试集。具体方法是删除某个特定节点发散的所有边。但此时这个节点就是孤立节点，图模型无法利用关于这个节点的任何信息用于推测。
>
> 例如，删除奥巴马的所有边，对于文本提取信息来说，仍可能通过其他位置的信息来推断，但是对于图模型来说是不可能的。
>
> 妥协策略：只删除某个节点的某一种边，但是随机采样模型可能会更倾向于扩展现有数据库的关系，而不是推断新加入的三元组关系。（懒）

## 2.Local closed world assumption

> 通过监督学习方法来计算三元组的正确率，LCWA方法用来确定样本的标签（训练集和测试集采用一个方法）

> 对于Freebase的triple标记为true。
>
> 对于需要求证的三元组采用启发式学习方法：
>
> - 定义O(s，p)为：在Freebase中，给定s和p所对应的o取值的集合。可能包含0到无穷个元素。
> - 对于候选的（s，p，o），满足以下条件

$$
\left\{
\begin{aligned}
correct,  (s，p，o) &\in O(s，p)\\
incorrect, (s，p，o) &\notin O(s，p)  \quad \&  \quad|O(s，p)|>0\\
\end{aligned}
\right.
$$

> 特别的，如果O(s，p)是空的，去掉该候选。

## 3.Fact Extraction From Web

### 提取方法

### 1Text Document（TXT）

> 对文档使用NLP工具，进行实体识别（Entity Recognition，演讲标记，依赖解析，指代消解的一部分工作）和实体链接（Entity Linkage，把文档中出现的名词，和KB中相应的实体的指代进行映射）。

> 然后训练提取器：对于网络的每一个关系，提取知识库中包含这个关系的实体对集合（s，o）s。
>
> 然后把这些实体对所在的句子进行特征提取/模式提取。

> 在bootstrapping阶段，利用提取的特征/模式，寻找更多包含相同实体类别的，模式能匹配的句子。
>
> 对这些句子用之前的LCWA方法进行标签。
>
> 对标签的训练集，使用MapReduce框架，对每一个分类器进行并行训练（这里使用logistic Regression）。

### 2HTML trees（DOM）

> 其实就是html的缩进格式，就是一个个html文档。
>
> 和前一种方法类似 ，只是我们从html文档中获取连接实体的特征。

上述两种方法的候选三元组评分都是分类器的输出结果：Pr(G(s,p,o))=1|.)

### 3HTML tables（TBL）

> 实体关系一般在文档的列头上，而不是接近文本和树的内容，因此我们用一种启发性方法。
>
> - 进行实体链接。
> - 尝试通过观察列实体，来识别每一列内的可能存在的关系。
> - 通过和Freebase对比，推理每一列对应于什么样的p（采用和标准模式匹配方法（standard schema matching method）相同的方法）。

候选三元组评分为named entity linkage system返回的置信度。

### 4Human Annotation pages（ANO）

> 知识库中没有这种类型的关系信息，因此手动在Freebase构造14种与人相关的关系，和注释到关系的映射。
>
> 得分同3

### 融合不同的提取器

> 一种简单的信号融合方式：对每个提取的三元组构造特征向量，然后通过分类器计算先验概率。

$$
\vec{f}(t)\quad for \quad t=(s,p,o)\\
\vec{f}(t)\Rightarrow binary \quad classifier  \Rightarrow Pr(t=1|\vec{f}(t))
$$

> 特征向量由每个分类器的两个参数构成：分类器提取源的数量的平方根，以及该提取器所有提取三元组的得分score的平均值。
>
> 分类器对收到的特征向量的每个分量使用不同的权重，可以学习整个系统的相对可信度和每个系统独立的可信度。

### 概率估计校准

> 置信度得分根据数据来源不同，有着不同的基数，要先标准化后再转化成概率。
>
> 利用Platt Scaling工具，用一个逻辑回归函数和验证集（Validation test）来让得分可以转化成概率。

### 方法比较

- 产生数据量：DOM > TXT > ANO > TBL
- AUC（真实性度量）（等价于分类器把正例判成负例的概率），这个数据表示了即使模型产生了大量的低置信度数据，系统也能识别出这些关系是不可靠的。AUC值最高的能够起到主宰融合后系统的作用。

### 添加更多证据（验证）模型的收益

> 三元组的概率/得分随抽取系统的数量而改变。
>
> 对于没有抽取系统的三元组，只能依赖与先验知识；此时先验正例概率为0.5，负例为0；
>
> 当我们积累了足够多的、有利于该三元组的证据时，正例概率接近1，负例低于0.5；
>
> ![image-20221013211123031](C:\Users\8208191402\AppData\Roaming\Typora\typora-user-images\image-20221013211123031.png)

>对于每个证据，采取每个域名下的网页只统计一次，而不是每个URL一次，防止多次统计。

## 4.图结构的先验模型构建

> 本文通过利用Freebase已有的三元组来训练先验模型。这个模型可以给任何三元组提供置信概率，即使网络上没有相关的证据，称之为图的连接预测。

### Path Ranking algorithm方法

>1.选择一对具有某种关系的实体entites
>
>2.从库中所有的subject随机行走，能到达object的路径算成功,例如夫妻关系可以由共同的孩子推断
>$$
>X \rightarrow Z \leftarrow Y
>$$
>或者曾祖父可以由两层父亲关系推断
>$$
>X \rightarrow Z \rightarrow Y
>$$
>路径的质量由支持度和准确度确定，每条正确路径推导出一条规则rule

> 一对实体可能经过多条路径，因此通过一个二值分类器来结合表示（这里用逻辑回归）。
>
> 分类器输入的特征是从s到o，不同路径的概率；分类器使用标签来自Local closed world assumption

> 测试时，对于给定（s，p，o），查询学习模型给出的、所有能实现p的可行路径（paths）。
>
> 每条路径为分类器提供一个特征的值。

### Neural network model方法

>另一种方法是把链接预测问题视作矩阵补全。
>
>原始的KB可以表示成一个稀疏的E×P×E的稀疏3维矩阵G，当存在（s，p，o）时G（s，p，o）=1，否则为0

> 我们通过为每一个实体entity和联系predicate，关联一个低维向量的方法，来实现张量拆解。
> $$
> Pr(G(s,p,o)=1)=\rho(\Sigma_{i=1}^K\upsilon_{si}\upsilon_{pi}\upsilon_{oi})\\
> \rho(x)=1/(1+e^{-x})\\
> 计算内积\\
> \vec{\upsilon}_s,\vec{\upsilon}_p,\vec{\upsilon}_o是k维向量
> $$
> 低维化的向量表示可以把分离在不同实体空间的s、o和p在低维语义上建立关系。
>
> 另一种张量化的低维表示：
> $$
> Pr(G(s,p,o)=1)=\rho(\vec{\beta_{p}}^{T}f[\vec{\upsilon_{s}}^{T}\vec{W_{p}}^{1:M}\vec{\upsilon_{o}}])\\
> \rho和之前相同，f取非线性函数，例如tanh\\
> \vec{\beta_{p}}是一个K*1维向量，\vec{W_{p}}^{m}是一个K*K维向量，M是tensor的总层数
> $$
> 本文简单选择只有一个标准化多层感知机；来获得相互作用p的术语
> $$
> Pr(G(s,p,o)=1)=\rho(\vec{\beta}^{T}f[\vec{A}[\vec{\upsilon_{s}},\vec{\omega_{p}},\vec{\upsilon_{o}}]])\\
> \vec{\beta}^{T}是一个1*L维向量,A是一个L×3K的矩阵，对应后面s，p，o各是k维向量\\
> 参数总数：O(L+L(K+E+P))
> $$
> 我们选择通过寻找K维空间中，不同单元（spo映射过来的向量）最近的n个邻居来判断：
>
> 模型是否学习了有意义的、对实体和关系的语义表征。
>
> 因为同类实体本身具有聚类特性，因此寻找关系的n个近邻。
>
> 例如，‘children’关系和‘parents’，‘spouse’，‘birthplace’等关系接近，说明了我们模型的可靠性。

### Fusing priors 先验融合

> 使用和3.2相同的方法进行融合，但这里的特征向量是，每一个不同先验系统的置信度 + 一个关于该子系统是否具有预测能力的指示器，而不是网络上相关文本的特征向量。

> 同样使用这些特征的boost classfier和Platt Scaling校准方法。

> 两个先验模型结合可以优势互补，因为两个先验模型的归纳偏置（Inductive biases）不同。
>
> 归纳偏置，通过超参数让算法优先计算某个问题。
>
> 例如贝叶斯算法中的先验分布、使用某些正则项来惩罚模型、设计某种特殊的网络结构

## 5.网络知识提取和先验的结合

> 先验的贡献在于减少了FP。
>
> 结论表明通过Local closed world assumption近似标签的数据仍然比人工标注的效果好。
